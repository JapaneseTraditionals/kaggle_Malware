{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Optuna debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T21:56:20.616495Z",
     "start_time": "2019-01-04T21:56:19.659971Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' #OSX\n",
    "import sys\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dask import dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import lightgbm as lgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T21:47:28.987618Z",
     "start_time": "2019-01-04T21:47:28.981027Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\"\n",
    "    Reduce memory usage\n",
    "    This function was developed by @icebee\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T21:47:28.992302Z",
     "start_time": "2019-01-04T21:47:28.989488Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = Path(\".\").absolute().parents[0]\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T21:49:11.250113Z",
     "start_time": "2019-01-04T21:49:11.228420Z"
    }
   },
   "outputs": [],
   "source": [
    "nrows = 300\n",
    "train_df = pd.read_csv(\n",
    "    ROOT_PATH / \"data\" / \"validations\" / \"train_sorted.csv\",\n",
    "    nrows = nrows\n",
    ")\n",
    "with ProgressBar():\n",
    "    train_df = reduce_mem_usage(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T22:46:09.434389Z",
     "start_time": "2019-01-04T22:46:09.425355Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"IsTest\"] = 0\n",
    "train_df.loc[train_df[\"Predict\"]>0.000002, \"IsTest\"] = 1\n",
    "x = train_df.drop([\"IsTest\"], axis=1)\n",
    "y = train_df.IsTest\n",
    "N_FOLDS = 5\n",
    "folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T22:28:44.712603Z",
     "start_time": "2019-01-04T22:28:44.700433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MachineIdentifier</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>6f461ad5a90da5672367a286ad8f1187</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>e8262d59d7f1f5946117667b0a1335c0</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1025043f37bcc75dd12500c0f574eaba</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>05043f16e58785017c2fc36831cdb351</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>56cc42df9b6bbc9b4bd1c79e7de9c532</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MachineIdentifier   Predict\n",
       "295  6f461ad5a90da5672367a286ad8f1187  0.000005\n",
       "296  e8262d59d7f1f5946117667b0a1335c0  0.000005\n",
       "297  1025043f37bcc75dd12500c0f574eaba  0.000005\n",
       "298  05043f16e58785017c2fc36831cdb351  0.000005\n",
       "299  56cc42df9b6bbc9b4bd1c79e7de9c532  0.000005"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T22:28:45.066118Z",
     "start_time": "2019-01-04T22:28:45.060981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295    1\n",
       "296    1\n",
       "297    1\n",
       "298    1\n",
       "299    1\n",
       "Name: IsTest, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna\n",
    "\n",
    "References\n",
    "- https://qiita.com/Tawasshy/items/699d8927860de6b37fe4\n",
    "- https://optuna.readthedocs.io/en/stable/reference/trial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T22:38:51.084926Z",
     "start_time": "2019-01-04T22:38:51.079923Z"
    }
   },
   "outputs": [],
   "source": [
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "\n",
    "    # sort rows on prediction column\n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "\n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
    "\n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "\n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred * 1. / G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T22:39:37.377533Z",
     "start_time": "2019-01-04T22:39:37.374938Z"
    }
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T23:23:12.606278Z",
     "start_time": "2019-01-04T23:23:12.596867Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-116-4e6d5d1416a5>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-116-4e6d5d1416a5>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 40 70)\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    device = \"cpu\"\n",
    "    objective = \"binary\"\n",
    "    boosting = trial.suggest_categorical('boosting', ['gbdt', 'gbrt', 'rf', 'random_forest', 'dart'])\n",
    "    num_leaves = trial.suggest_int('num_leaves', 40, 60)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 40 70)\n",
    "    param = {\n",
    "        'device': device,\n",
    "        'objective':objective,\n",
    "        \"boosting\": boosting,\n",
    "        'num_leaves': num_leaves,\n",
    "        'min_data_in_leaf': min_data_in_leaf, \n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.1,\n",
    "        \"feature_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"bagging_fraction\": 0.8 ,\n",
    "        \"bagging_seed\": 11,\n",
    "        \"metric\": 'auc',\n",
    "        \"lambda_l1\": 0.1,\n",
    "        \"random_state\": 133,\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "    num_boost_round = 1\n",
    "    verbose_eval = 100\n",
    "    early_stopping_rounds = 1\n",
    "    predictions = np.zeros(y.shape)\n",
    "    best_trees = []\n",
    "    fold_scores = []\n",
    "    x_score = []\n",
    "    for fold_, (train_fold, validate_fold) in enumerate(folds.split(x.values, y.values)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        X_train, X_validate, y_train, y_validate = x.iloc[train_fold], x.iloc[validate_fold], y.iloc[train_fold], y.iloc[validate_fold]\n",
    "\n",
    "        train_dataset = lgb.Dataset(X_train, y_train)\n",
    "        valid_dataset = lgb.Dataset(X_validate, y_validate)\n",
    "        clf = lgb.train(param, train_dataset, num_boost_round, valid_sets=valid_dataset,\n",
    "                        verbose_eval=verbose_eval, feval=evalerror, early_stopping_rounds=early_stopping_rounds)\n",
    "        best_trees.append(clf.best_iteration)\n",
    "        predict = clf.predict(X_validate, num_iteration=clf.best_iteration)\n",
    "        score = roc_auc_score(y_validate, predict)\n",
    "        print(\"AUC: {}\\n\".format(score))\n",
    "        fold_scores.append(score)\n",
    "        predictions[validate_fold] = predict\n",
    "    \n",
    "    return sum(fold_scores)/len(fold_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T23:21:44.233637Z",
     "start_time": "2019-01-04T23:21:43.551861Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/berry/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 0.986486\tvalid_0's gini: 0.952703\n",
      "AUC: 0.9864864864864865\n",
      "\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 0.972973\tvalid_0's gini: 0.905993\n",
      "AUC: 0.972972972972973\n",
      "\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-01-05 08:21:43,726] Finished a trial resulted in value: 0.991891891891892. Current best value is 0.991891891891892 with parameters: {'boosting': 'dart', 'num_leaves': 42}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 0.986486\tvalid_0's gini: 0.952703\n",
      "AUC: 0.9864864864864865\n",
      "\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 0.972973\tvalid_0's gini: 0.905993\n",
      "AUC: 0.972972972972973\n",
      "\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-01-05 08:21:43,886] Finished a trial resulted in value: 0.991891891891892. Current best value is 0.991891891891892 with parameters: {'boosting': 'dart', 'num_leaves': 42}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 0.986486\tvalid_0's gini: 0.952703\n",
      "AUC: 0.9864864864864865\n",
      "\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 0.972973\tvalid_0's gini: 0.905993\n",
      "AUC: 0.972972972972973\n",
      "\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-01-05 08:21:44,046] Finished a trial resulted in value: 0.991891891891892. Current best value is 0.991891891891892 with parameters: {'boosting': 'dart', 'num_leaves': 42}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 0.986486\tvalid_0's gini: 0.952703\n",
      "AUC: 0.9864864864864865\n",
      "\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 0.972973\tvalid_0's gini: 0.905993\n",
      "AUC: 0.972972972972973\n",
      "\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's gini: 1\n",
      "AUC: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-01-05 08:21:44,204] Finished a trial resulted in value: 0.991891891891892. Current best value is 0.991891891891892 with parameters: {'boosting': 'dart', 'num_leaves': 42}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2019-01-05 08:21:44,228] Setting trial status as TrialState.FAIL because of the following error: LightGBMError('Cannot use bagging in GOSS')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/berry/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/optuna/study.py\", line 400, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-113-8e8821c33950>\", line 37, in objective\n",
      "    verbose_eval=verbose_eval, feval=evalerror, early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"/Users/berry/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/lightgbm/engine.py\", line 195, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/berry/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/lightgbm/basic.py\", line 1512, in __init__\n",
      "    ctypes.byref(self.handle)))\n",
      "  File \"/Users/berry/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/lightgbm/basic.py\", line 46, in _safe_call\n",
      "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
      "lightgbm.basic.LightGBMError: Cannot use bagging in GOSS\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
