from feature_extractor import FeatureExtractor
from moco_classifier import MocoClassifier
from save_log import stop_watch, need_prediction
import pandas as pd
from pathlib import Path


class Processor():
    """
    For processing train and test
    """
    def __init__(self, feature_groups,
                 clf_type, clf_params, dataset_path):
        """
        Parameters
        feature_groups  <dict>      : features dictionary in json
        clf_type        <object>    : classifier type in json
        clf_params      <dict>      : classifier parameters in json
        dataset_path    <PosixPath> : input csv file path in json
        """
        self.feature_groups = feature_groups
        self.dataset_path = dataset_path
        self.valids = ["valid{}".format(str(n)) for n in range(5)]  # 勝手に決めた
        self.classifier = MocoClassifier(clf_type, clf_params, self.valids, dataset_name=dataset_path.name)

    def process(self):
        """
        (WIP)
        For processing train and test
            preprocess > train > predict
        """
        feature_names = self.__preprocess()
        validity = self.__train(feature_names)
        predict = self.__predict(feature_names) if need_prediction() else None
        return validity, predict

    def get_feature_df(self, dataset_name, feature_names, valid_dir, part):
        """
        Ex)
        dataset_name    : min, ...
        feature_names   : __preprocess() return
        valid_dir       : "valid0", "valid1", ...
        part            : "train", "validate", "test"
        """
        feature_df = None
        featureset_path = Path(__file__).absolute().parents[1] / "data" / "features" / dataset_name / valid_dir
        for group, feature_list in feature_names.items():
            df = pd.read_csv(featureset_path / "{}_{}.csv".format(part, group),
                             usecols=["MachineIdentifier"] + feature_list)
            if feature_df is None:
                feature_df = df
            else:
                feature_df = feature_df.merge(right=df,
                                              how="inner",
                                              on="MachineIdentifier")
        return feature_df

    @stop_watch("Processor.preprocess()")
    def __preprocess(self):
        """
        """
        feature_extractor = FeatureExtractor(self.dataset_path, self.feature_groups)
        for valid_dir in ["valid{}".format(str(n)) for n in range(5)]:
            print("\t\t=== {} : {:^10} ===".format(valid_dir, "train"))
            feature_extractor.extract(part="train", valid_dir=valid_dir)
            print("\t\t=== {} : {:^10} ===".format(valid_dir, "validate"))
            feature_extractor.extract(part="validate", valid_dir=valid_dir)
            if need_prediction():
                print("\t\t=== {} : {:^10} ===".format(valid_dir, "test"))
                feature_extractor.extract(part="test", valid_dir=valid_dir)
        return feature_extractor.get_feature_names()

    @stop_watch("Processor.train()")
    def __train(self, feature_names):
        """
        (WIP)
        Processing of train
        1. Feature Extraction
        2. Fitting train data with lgbm
        ---
        Return
        validity: validation output of this process
        """
        self.classifier.train(feature_names)
        validity = 0
        return validity

    @stop_watch("Processor.predict()")
    def __predict(self, feature_names):
        """
        (WIP)
        Processing of test
        1. Feature Extraction
        2. Predict test data with classifier obtained from process_train()
        """
        submit = self.classifier.predict(feature_names)
        return submit
