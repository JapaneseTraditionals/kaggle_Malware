import time
import gc
import numpy as np
import lightgbm as lgb
import optuna
from logging import getLogger
from save_log import get_version
from clf_util import eval_auc
from classifier.base_classifier import BaseClassifier
from classifier.lgbm_classifier import LGBMClassifier
from save_log import stop_watch, send_message


class LGBMOptunaOneClassifier(BaseClassifier):

    def objective(self, trial):
        # Extract optuna attribs from the input json
        optuna_trn_params = {}
        for key, val in self.params["trn_params"].items():
            if type(val) != list:
                optuna_trn_params[key] = val
            else:
                if type(val[0]) == float:
                    optuna_trn_params[key] = trial.suggest_uniform(key, val[0], val[1])
                elif type(val[0]) == int:
                    optuna_trn_params[key] = trial.suggest_int(key, val[0], val[1])
                else:
                    optuna_trn_params[key] = trial.suggest_categorical(key, val)

        start = time.time()
        getLogger(get_version()).info("\t [OPTUNA] {}th optimization starts".format(self.optimized_count))
        send_message("\t [OPTUNA] :sushi: {} th optimization starts".format(self.optimized_count))

        # Classify
        mtd_params = self.params["mtd_params"]
        clf = lgb.train(optuna_trn_params,
                        self.train_dataset,
                        mtd_params["num_boost_round"],
                        valid_sets=[self.train_dataset, self.valid_dataset],
                        feval=eval_auc,
                        verbose_eval=mtd_params["verbose_eval"],
                        early_stopping_rounds=mtd_params["early_stopping_rounds"])

        getLogger(get_version()).info("\t {}".format(clf.params))
        send_message("\t {}".format(clf.params))

        for train_or_valid, metrics in clf.best_score.items():
            for metric, score in metrics.items():
                getLogger(get_version()).info("\t\t >> Best {} {}: {}".format(train_or_valid, metric, score))
                send_message("\t\t :star-struck: Best {} {}: {}".format(train_or_valid, metric, score))

        # Post-process this fold
        elapsed_time = int(time.time() - start)
        minutes, sec = divmod(elapsed_time, 60)
        hour, minutes = divmod(minutes, 60)
        getLogger(get_version()).info(
            "\t [OPTUNA] >> {}th optimization finishes: [elapsed_time] >> {:0>2}:{:0>2}:{:0>2}"
            .format(self.optimized_count, hour, minutes, sec))
        send_message("\t [OPTUNA] :sushi: {}th optimiaztion finishes: [elapsed_time] >> {:0>2}:{:0>2}:{:0>2}".format(self.optimized_count, hour, minutes, sec))
        self.optimized_count += 1

        return clf.best_score["valid_1"]["binary_logloss"]

    @stop_watch("LGBMOptunaOneClassifier.train()")
    def train(self, feature_names):
        self.feature_names = feature_names

        fold = 0
        valid = "valid{}".format(str(fold))
        trn_x = super().get_feature_df(self.feature_names, valid, "train")
        val_x = super().get_feature_df(self.feature_names, valid, "validate")
        trn_x.set_index("MachineIdentifier", inplace=True)
        val_x.set_index("MachineIdentifier", inplace=True)
        trn_y = trn_x["HasDetections"].astype(np.int8)
        val_y = val_x["HasDetections"].astype(np.int8)
        del trn_x["HasDetections"], val_x["HasDetections"]
        self.train_dataset = lgb.Dataset(trn_x, trn_y)
        self.valid_dataset = lgb.Dataset(val_x, val_y)
        self.optimized_count = 0

        study = optuna.create_study()
        study.optimize(self.objective, n_trials=self.params["n_trials"])
        best_trn_params = study.best_params
        getLogger(get_version()).info("\t >> Best params: {}".format(best_trn_params))
        send_message("\t :youzyo: Best params: {}".format(best_trn_params))

        for key, val in self.params["trn_params"].items():
            if type(val) != list:
                best_trn_params[key] = val
        self.params["trn_params"] = best_trn_params
        del self.train_dataset, self.valid_dataset
        gc.collect()

        self.best_lgbm_classifier = LGBMClassifier(self.params, self.dataset_name)
        return self.best_lgbm_classifier.train(feature_names)

    @stop_watch("LGBMClassifier.predict()")
    def predict(self, feature_names):
        return self.best_lgbm_classifier.predict(feature_names)
