import time
import copy
import numpy as np
import torch
from itertools import chain
from logging import getLogger
from clf_util import fast_auc
from torch.utils.data import DataLoader, TensorDataset
from save_log import get_version, get_training_logger, send_message


def create_tensor_dataloader(params, trn_x, trn_y, val_x, val_y):
    # Generate train_loader
    trn_x_tensor = torch.tensor(trn_x.values.astype(np.float32))
    trn_y_tensor = torch.tensor(trn_y)
    trn_dataset = TensorDataset(trn_x_tensor, trn_y_tensor)
    train_loader = DataLoader(dataset=trn_dataset, batch_size=params["batch_size"], shuffle=True)

    # Generate valid_loader
    val_x_tensor = torch.tensor(val_x.values.astype(np.float32))
    val_y_tensor = torch.tensor(val_y)
    val_dataset = TensorDataset(val_x_tensor, val_y_tensor)
    valid_loader = DataLoader(dataset=val_dataset, batch_size=params["batch_size"], shuffle=False)

    dataset_sizes = {"train": len(trn_dataset),
                     "valid": len(val_dataset)}
    return train_loader, valid_loader, dataset_sizes


def train_model(fold, validity, val_x,
                data_loaders, dataset_sizes, model,
                criterion, optimizer, scheduler,
                num_epochs, early_stopping_rounds=10):
        since = time.time()
        best_score = {
            "train BCELoss": 1.0,
            "train AUC": 0.5,
            "valid BCELoss": 1.0,
            "valid AUC": 0.5}
        best_model_wts = copy.deepcopy(model.state_dict())
        get_training_logger(get_version()).debug(
            "fold \t iteration \
            \t train BCELoss \t valid AUC \
            \t valid BCELoss \t valid AUC")
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        model = model.to(device)

        not_improve_round = 0
        for epoch in range(num_epochs):
            bce_dictionary = {"train": 0.0, "valid": 0.0}
            auc_dictionary = {"train": 0.0, "valid": 0.0}
            for phase in ["train", "valid"]:
                if phase == "train":
                    scheduler.step()
                    model.train()
                else:
                    model.eval()

                running_bce = 0.0
                running_auc = 0.0

                # Iteration
                for inputs, labels in data_loaders[phase]:
                    inputs = inputs.to(device)
                    labels = labels.to(device)

                    optimizer.zero_grad()

                    # forward
                    with torch.set_grad_enabled(phase == "train"):
                        outputs = model(inputs)
                        loss = criterion(outputs, labels)

                        # backward + optimize
                        if phase == "train":
                            loss.backward()
                            optimizer.step()
                    # statistics
                    running_bce += loss.item() * inputs.size(0)
                    if torch.cuda.is_available():
                        labels = labels.cpu()
                        outputs = outputs.cpu()
                    y_true = labels.numpy()
                    y_pred = list(chain.from_iterable(outputs.detach().numpy()))
                    running_auc += fast_auc(y_true, y_pred) * inputs.size(0)
                bce_dictionary[phase] = running_bce / dataset_sizes[phase]
                auc_dictionary[phase] = running_auc / dataset_sizes[phase]

            # Update model
            if best_score["train BCELoss"] > bce_dictionary["train"]:
                best_score["train BCELoss"] = bce_dictionary["train"]
                best_score["valid BCELoss"] = bce_dictionary["valid"]
                best_score["train AUC"] = auc_dictionary["train"]
                best_score["valid AUC"] = auc_dictionary["valid"]
                best_model_wts = copy.deepcopy(model.state_dict())
                not_improve_round = 0
            else:
                not_improve_round += 1

            if not_improve_round >= early_stopping_rounds:
                getLogger(get_version()).info(
                    "\t \t Epoch {}/{}: Early stopping".format(epoch, num_epochs))
                send_message(
                    "\t \t :scream: Epoch {}/{}: Early stopping".format(epoch, num_epochs))
                break

            get_training_logger(get_version()).debug("{}\t{}\t{}\t{}\t{}\t{}".format(
                fold, epoch, bce_dictionary["train"], bce_dictionary["valid"],
                auc_dictionary["train"], auc_dictionary["valid"]))

        time_elapsed = time.time() - since
        getLogger(get_version()).info(
            "\t \t Training complete in {:.0f}m {:.0f}s".format(time_elapsed // 60, time_elapsed % 60))
        send_message(
            "\t \t Training complete in {:.0f}m {:.0f}s".format(time_elapsed // 60, time_elapsed % 60))

        getLogger(get_version()).info(
            "\t \t [Best train scores] BCELoss: {:.4f}, AUC: {:.4f}".format(
                best_score["train BCELoss"], best_score["train AUC"]))
        getLogger(get_version()).info(
            "\t \t [Valid scores when train is the best] BCELoss: {:.4f}, AUC: {:.4f}".format(
                best_score["valid BCELoss"], best_score["valid AUC"]))

        send_message("\t \t :star-struck: Best train BCELoss: {:.4f}".format(best_score["train BCELoss"]))
        send_message("\t \t :star-struck: Best train AUC: {:.4f}".format(best_score["train AUC"]))
        send_message("\t \t :star-struck: Best valid BCELoss: {:.4f}".format(best_score["valid BCELoss"]))
        send_message("\t \t :star-struck: Best valid AUC: {:.4f}".format(best_score["valid AUC"]))

        model.load_state_dict(best_model_wts)
        return model
