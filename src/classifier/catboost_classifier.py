import gc
import time
from pathlib import Path
import numpy as np
import pandas as pd
import logging
from logging import getLogger
from catboost import CatBoost, CatBoostClassifier
from clf_util import fast_auc, eval_auc
from classifier.base_classifier import BaseClassifier
from save_log import stop_watch, get_back_training, get_training_logger, train_one_round, get_version


class CATClassifier(BaseClassifier):

    @stop_watch("CATClassifier.train()")
    def train(self, feature_names):
        """
        Input:
            feature_names: directionary of features' names
        Output:
            validity: Dataframe(["MachineIdentifier", "HasDetections", "Predict")
        """
        # Initialize parameters
        clfs = []
        validity = None
        model_path = Path(__file__).absolute().parents[2] / "data" / "model" / str(get_version())
        Path.mkdir(model_path, exist_ok=True, parents=True)
        feature_importance = pd.DataFrame()
        START_FOLD = 0
        if get_back_training():
            START_FOLD = len(list(model_path.glob('**/*.model')))
        END_FOLD = 5
        if train_one_round():
            START_FOLD = 0
            END_FOLD = 1
        if START_FOLD == END_FOLD:
            return None

        # Process for each fold
        for fold in range(START_FOLD, END_FOLD):
            # Measure start time of the classification of this fold
            start = time.time()
            getLogger(get_version()).info("\t >> {} folds start".format(fold))

            # Generate dataset
            valid = "valid{}".format(str(fold))
            trn_x = super().get_feature_df(feature_names, valid, "train")
            val_x = super().get_feature_df(feature_names, valid, "validate")
            trn_x.set_index("MachineIdentifier", inplace=True)
            val_x.set_index("MachineIdentifier", inplace=True)
            trn_y = trn_x["HasDetections"].astype(np.int8)
            val_y = val_x["HasDetections"].astype(np.int8)

            # Initialize variables for scoring
            if validity is None:
                validity = pd.DataFrame()
                validity["HasDetections"] = pd.concat([trn_y, val_y])
                validity["Predict"] = 0

            # Delete needless features
            del trn_x["HasDetections"], val_x["HasDetections"]

            # Classify
            clf = CatBoostClassifier(iterations=self.params["iterations"],
                                     verbose=self.params["verbose"],
                                     early_stopping_rounds=self.params["early_stopping_rounds"],
                                     learning_rate=self.params["learning_rate"],
                                     random_seed=self.params["random_seed"],
                                     max_depth=self.params["max_depth"],
                                     loss_function=self.params["loss_function"],
                                     custom_metric=self.params["custom_metric"],
                                     eval_metric=self.params["eval_metric"],
                                     l2_leaf_reg=self.params["l2_leaf_reg"],
                                     rsm=self.params["rsm"])
            clf.fit(trn_x.values, trn_y.values,
                    eval_set=(val_x.values, val_y.values))
            validity.loc[validity.index.isin(val_x.index), "Predict"] = clf.predict(val_x.values)

            # Calculate feature importance per fold
            if fold == 0:
                feature_importance["feature"] = trn_x.columns
            feature_importance["fold{}".format(fold)] = clf.get_feature_importance()

            # Measure finish time of the classification of this fold
            elapsed_time = int(time.time() - start)
            minutes, sec = divmod(elapsed_time, 60)
            hour, minutes = divmod(minutes, 60)
            getLogger(get_version()).info(
                "\t >> {} folds finish: [elapsed_time] >> {:0>2}:{:0>2}:{:0>2}"
                .format(fold, hour, minutes, sec))

            # Post-process this fold
            clfs.append(clf)
            clf.save_model(str(model_path / "valid{}.model".format(fold)))

        # Output CV score
        validity = validity.reset_index()
        columns_order = ["MachineIdentifier", "HasDetections", "Predict"]
        validity = validity.sort_values("MachineIdentifier").reset_index(drop=True).loc[:, columns_order]
        cv_auc = (fast_auc(validity["HasDetections"], np.array(validity["Predict"])))
        getLogger(get_version()).info("\t >> CV Score (AUC):{}".format(cv_auc))

        # Save importance
        feature_importance.set_index("feature", inplace=True)
        feature_importance["median"] = feature_importance.median(axis='columns')
        feature_importance.sort_values("median", ascending=False, inplace=True)
        directory_path = Path(__file__).absolute().parents[2] / "importance"
        Path.mkdir(directory_path, exist_ok=True, parents=True)
        feature_importance.to_csv(Path(directory_path / "{}.csv".format(get_version())))

        # Post-process the training
        del feature_importance
        gc.collect()

        return validity

    @stop_watch("CATClassifier.predict()")
    def predict(self, feature_names):
        """
        Input:
            feature_names: directionary of features' names
        Output:
            predict_df: Dataframe(["MachineIdentifier", "HasDetections")
        """
        model_directory_path = Path(__file__).absolute().parents[2] / "data" / "model" / str(get_version())
        preds = None
        FOLDS = 5
        predict_df = None
        for fold in range(FOLDS):
            model_path = model_directory_path / "valid{}.model".format(fold)
            clf = CatBoostClassifier()
            clf.load_model(fname=str(model_path))
            valid = "valid{}".format(fold)
            test_df = super().get_feature_df(feature_names, valid, "test")
            if predict_df is None:
                predict_df = test_df["MachineIdentifier"]
            test_df = test_df.set_index("MachineIdentifier")
            if preds is None:
                preds = self.predict_chunk(clf, test_df) / FOLDS
            else:
                preds += self.predict_chunk(clf, test_df) / FOLDS

        predict_df = pd.DataFrame(predict_df)
        predict_df["HasDetections"] = preds
        return predict_df

        return predict_df

    def predict_chunk(self, model, test):
        initial_idx = 0
        chunk_size = 1000000
        current_pred = np.zeros(len(test))
        while initial_idx < test.shape[0]:
            final_idx = min(initial_idx + chunk_size, test.shape[0])
            idx = range(initial_idx, final_idx)
            current_pred[idx] = model.predict(test.iloc[idx])
            initial_idx = final_idx
        return current_pred
