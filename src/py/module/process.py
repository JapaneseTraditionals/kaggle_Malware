from module.get_option import *
from module.import_libs import *
from module.load_csv import *
from module.load_validation import *
from module.save_log import *
from module.use_features import *
from module.use_lgbm import *

ROOT_PATH = Path(__file__).absolute().parents[2]

def preprocess_dd(ddf, pre_list):
    return ddf

def preprocess_pd(df, pre_list):
    return df


@stop_watch
def clean(is_train):
    train_dtype = read_csv_dtype(is_train=is_train)
    ddf = "hoge" # Read csv
    
    load_ddf = load_features(ROOT_PATH, is_train=is_train)
    # load_features * n
    # join features
    pre_list = ['hoge'] # Create list of column names of df or ddf

    ddf = preprocess_dd(ddf, pre_list)
    df = ddf # df = ddf.compute()
    df = preprocess_pd(df, pre_list)

    return df

@stop_watch
def process_train(columns, lgbm_params):
    df = clean(is_train=True)

    clf = fit_train(df, lgbm_params)

    save_features(df, "hoge", ROOT_PATH, is_train=True)
    # save_features * n

    return clf

@stop_watch
def process_test(columns, clf):
    df = clean(is_train=False)

    submit = predict_test(df, clf)

    save_features(df, "hoge", ROOT_PATH, is_train=False)
    # save_features * n

    return submit

def process(args, columns, lgbm_params):
    clf = process_train(columns, lgbm_params)
    if not args.dontPredict:
        submit = process_test(columns, clf)

