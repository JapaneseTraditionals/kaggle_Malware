from pathlib import Path
import numpy as np
import pandas as pd
import json
from classifier_type import ClassifierType
from logging import getLogger
from processor import Processor
from save_log import get_version, need_prediction, only_prediction
from exceptions import DuplicateVersionException
from clf_util import fast_auc


class ProcessorFactory():

    ROOT_PATH = Path(__file__).absolute().parents[1]

    @classmethod
    def process(cls, args):
        """
        main method
        """

        # Split the config file ({version}.json) into each variable
        config_file = cls.__load_config(args.version)
        with config_file.open() as f:
            params_dict = json.load(f)
        validities = []
        predicts = []
        trained_fully_before_processing = False
        for name, params in params_dict.items():
            feature_groups = params["Preprocess"]
            clf_type = params["Classifier"]
            clf_params = params["ClassifierParams"]
            dataset_path = cls.ROOT_PATH / params["DatasetPath"]
            processor = Processor(feature_groups,
                                  ClassifierType.parseType(clf_type),
                                  clf_params, dataset_path)
            validity, predict = processor.process()
            if validity is None:
                trained_fully_before_processing = True
            else:
                validities.append(validity)
            predicts.append(predict)
            ProcessorFactory.__print_log(name, clf_type, dataset_path)

        # Output total CV Score
        if trained_fully_before_processing is False and only_prediction() is False:
            valid_df = cls.__save_outputs(validities, is_train=True)
            total_cv = fast_auc(valid_df["HasDetections"], np.array(valid_df["Predict"]))
            getLogger(get_version()).info("\t >> Total CV Score (AUC): {}".format(total_cv))

        # Output submit file
        if need_prediction() or only_prediction():
            cls.__save_outputs(predicts, is_train=False)

    @classmethod
    def __load_config(cls, version):
        """
        version : string
        return  : PosixPath
        """
        version_file_list = list(cls.ROOT_PATH.glob("config/" + version + "*.json"))
        if len(version_file_list) > 1:
            raise DuplicateVersionException()
        return version_file_list[0]

    @classmethod
    def __save_outputs(cls, outputs, is_train):
        """
        is_train = True  -> Save ground truth and validity of train dataset
        is_train = False -> Save predictions of test dataset
        """
        if is_train:
            columns_order = ["MachineIdentifier", "HasDetections", "Predict"]
            save_path = cls.ROOT_PATH / "data" / "oof"
        else:
            columns_order = ["MachineIdentifier", "HasDetections"]
            save_path = cls.ROOT_PATH / "data" / "submit"
        Path.mkdir(save_path, exist_ok=True, parents=True)

        save_df = None
        for output in outputs:
            if save_df is None:
                save_df = output
            else:
                save_df = pd.concat([save_df, output])
        submission_df = pd.read_csv(cls.ROOT_PATH / "input" / "sample_submission.csv")
        del submission_df["HasDetections"]
        if is_train is False:
            predict_length = len(save_df)
            sub_length = len(submission_df)
            if predict_length != sub_length:
                getLogger(get_version()).info("CAUSION: Length of predict_df ({}) is NOT equal to that of submisson_df ({})".format(predict_length, sub_length))
            save_df = pd.merge(save_df, submission_df, on="MachineIdentifier", how='right')
        save_df = save_df.sort_values("MachineIdentifier").reset_index(drop=True).loc[:, columns_order]
        filename = save_path / "{}.csv".format(get_version())
        save_df.to_csv(filename, index=False, float_format="%.6f")
        getLogger(get_version()).info("Output {}.".format(filename))

        return save_df

    @classmethod
    def __print_log(cls, name, clf_type, dataset_path):
        version = get_version()
        getLogger(version).info("================================")
        getLogger(version).info("Processor Name: {}".format(name))
        getLogger(version).info("Classifier Type: {}".format(clf_type))
        getLogger(version).info("Input Path: {}".format(dataset_path))
        getLogger(version).info("================================")
