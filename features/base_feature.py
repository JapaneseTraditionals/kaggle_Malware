from sys import stdout
from abc import ABCMeta, abstractmethod
import warnings
from pathlib import Path
import pandas as pd
import dask.dataframe as dd
import fasteners
from joblib import Parallel, delayed
from features.get_dtype import get_csv_dtype
from features.feature_calculator import feature_calculator
from exceptions import IrregularArgumentException
from save_log import get_njobs, get_recalcFeature
warnings.filterwarnings('ignore')


class BaseFeature(metaclass=ABCMeta):

    def __init__(self, features, input_path, output_path):
        '''
        features    <dict>   : groupごとの各種特徴量名
        input_path  <string> : 対象データが保存されているディレクトリ
        output_path <string> : True > train, False > test
        '''
        self.features = features
        self.input_path = input_path
        self.output_path = output_path
        self.valid_dir = output_path.parent.name
        self.dataset_path = input_path.parent if input_path.name == "test.csv" else input_path.parents[1]
        self.lock = fasteners.InterProcessLock('tmp/tmp_lock_file')
        self.calculator = None

        self.output_path.parent.mkdir(parents=True, exist_ok=True)

    @abstractmethod
    def get_loadcols(self):
        """
        return
            : columns list
        """
        pass

    @abstractmethod
    def extract(self):
        '''
        1. 計算の必要性の確認
        2. 必要であれば計算し保存(pandas base)
        3. 展開した特徴量をlistで返す
        '''
        def calcFratures(feature_name, feature_params):
            new_feature_df = self.calculator.calc(**feature_params)

            cols = list(new_feature_df.columns)[1:]
            if len(cols) == 1:
                new_feature_df.columns = ["MachineIdentifier", feature_name]
            elif len(cols) > 1:
                new_feature_df.columns = ["MachineIdentifier"] + [feature_name + "_" + c for c in cols]

            # progress output
            self.lock.acquire()
            try:
                stdout.write("\r[Group] {:<15} >> multiprocessing : Done {:>3} out of {:>3} latest {:<100}".format(
                    self.__class__.__name__,
                    str(self.checkJobProgress()),
                    str(len(needCalculationFeatures)),
                    "\"" + feature_name + "\""))
            finally:
                self.lock.release()

            return new_feature_df

        # needCalculationFeatures
        featuresFromula = self.getFeaureFromulas()
        featureNameList = list(featuresFromula.keys())
        needCalculationFeatures = {fn: featuresFromula[fn] for fn in featureNameList if not self.isCalculated(fn)}
        # recalc
        if get_recalcFeature() is not None:
            need_recalc_list = list((set(get_recalcFeature()) & set(featureNameList)))
            for key in need_recalc_list:
                needCalculationFeatures[key] = featuresFromula[key]
        # calc feature
        if len(needCalculationFeatures) > 0:
            train_df = pd.read_csv(self.dataset_path / self.valid_dir / "train.csv",
                                   dtype=get_csv_dtype(),
                                   usecols=["MachineIdentifier"] + self.get_loadcols() + ["HasDetections"])
            validate_df = pd.read_csv(self.dataset_path / self.valid_dir / "validate.csv",
                                      dtype=get_csv_dtype(),
                                      usecols=["MachineIdentifier"] + self.get_loadcols() + ["HasDetections"])
            test_df = pd.read_csv(self.dataset_path / "test.csv",
                                  dtype=get_csv_dtype(),
                                  usecols=["MachineIdentifier"] + self.get_loadcols())
            self.calculator = feature_calculator(self.input_path.stem, train_df, validate_df, test_df)
            print("[Group] {:<15} >> multiprocessing : Done {:>3} out of {:>3}".format(
                self.__class__.__name__,
                self.checkJobProgress(is_init=True),
                str(len(needCalculationFeatures))), end="", flush=True)
            new_features_list = Parallel(n_jobs=get_njobs())(
                [delayed(calcFratures)(feature_name, feature_params) for feature_name, feature_params in needCalculationFeatures.items()])
            print("", flush=True)

            # feature dataframe
            new_feature_df = new_features_list[0].loc[:, ["MachineIdentifier"]]
            new_features_list = [df.iloc[:, 1:] for df in new_features_list]
            new_feature_df = pd.concat([new_feature_df] + new_features_list, axis=1)

            self.saveNewFeature(new_feature_df)

        # OneHotEncoding
        OneHotfeatureList = [fn for fn in featureNameList if fn.endswith("OneHotEncoding")]
        featureNameList = [fn for fn in featureNameList if not fn.endswith("OneHotEncoding")]
        for ohf in OneHotfeatureList:
            featureNameList = featureNameList + self.getOneHotFeatureName(ohf)

        return featureNameList

    def isCalculated(self, feature_name):
        '''
        feature_name = {Group_name}_{attribute_name}
        {part}_{group_name}.csvが存在し，かつcsvの一行目にfeature_nameが確認できた場合にTrueを返す．
        '''
        isCalculated = False
        if self.output_path.exists():
            with self.output_path.open() as f:
                columns = f.readline().rstrip("\n\r").split(",")
            if feature_name in columns:
                isCalculated = True
            elif ("OneHotEncoding" in feature_name) & (sum([c.startswith(feature_name) for c in columns]) > 0):  # for OneHotEncoding
                isCalculated = True
        return isCalculated

    def getFeaureFromulas(self):
        """
        [group_name]_[function_name]_[columns_name]_[args_name]_[encode_name]
        """
        group_name = self.__class__.__name__
        feature_dict = {}
        for func_name, func_params_list in self.features.items():
            for func_params in func_params_list:
                # set feature_name
                feature_name = "_".join([group_name, func_name] + func_params["columns"])
                if "args" in func_params:
                    feature_name = "_".join([feature_name] + [str(v) for v in func_params["args"].values()])
                else:
                    func_params["args"] = {}
                if "encode" in func_params:
                    feature_name = feature_name + "_" + func_params["encode"]

                # eval function
                func_params["func"] = eval("self." + func_name)

                feature_dict[feature_name] = func_params
        return feature_dict

    def saveNewFeature(self, new_feature_df):
        '''
        作成した特徴量を受け取りすでに作成している特徴量と合わせてcsvで保存する．
        new_feature_df  <pandas.Dataframe>
          columns = [MachineIdentifier, {feature_name1}, {feature_name2}, ...]
          new_feature_df.sort_values("MachineIdentifier").reset_index(drop=True)をかけてからinputすること
        '''
        if self.output_path.exists():
            new_col = new_feature_df.columns.tolist()[1:]
            feature_df = dd.read_csv(self.output_path).compute()
            feature_df[new_col] = new_feature_df[new_col]
        else:
            feature_df = new_feature_df
        feature_df.to_csv(self.output_path, index=False)

    def checkJobProgress(self, is_init=False):
        path = Path("tmp")
        path.mkdir(exist_ok=True)
        path = path / "job_num"
        if is_init:
            job_num = 0
            with path.open(mode="w") as f:
                f.write(str(job_num))
        else:
            with path.open(mode="r") as f:
                job_num = int(f.read())
            with path.open(mode="w") as f:
                job_num += 1
                f.write(str(job_num))
        return job_num

    def getOneHotFeatureName(self, prefixOneHotFeatureName):
        with self.output_path.open() as f:
            columns = f.readline().rstrip("\n\r").split(",")
        return [c for c in columns if c.startswith(prefixOneHotFeatureName)]
